{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lotusist/MachineLearning-DeepLearning/blob/main/hw1_multilinearreg_logit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXUzC0Yv5Vse"
      },
      "source": [
        "# MLDL1 2022 Spring\n",
        "## Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOf2_jb3siTn"
      },
      "source": [
        "# 0. Setting Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7XnungPxbcs",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amOT2LDIunKq"
      },
      "outputs": [],
      "source": [
        "_path = 'C:/Users/gsds/Desktop/MLDL1'\n",
        "data_list = ['Carseats', 'Default']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0paiXw_JwcS_"
      },
      "outputs": [],
      "source": [
        "cs = pd.read_csv(_path + '/' + data_list[0] + '.csv', low_memory = False)\n",
        "df = pd.read_csv(_path + '/' + data_list[1] + '.csv', low_memory = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtAlIj5n2VF6"
      },
      "source": [
        "# 1. Carseats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-BKRbpbtOYJ"
      },
      "source": [
        "## (a) Fit a multiple linear regression model to predict Sales using Price, Urban,and US. Report the $ R^2 $ of the model.\n",
        " - The $ R^2 $ of the model is **0.239**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "9__laeEXzAE4",
        "outputId": "d500574a-0f0a-4a2f-dfff-08a6c89c4ee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Sales   400 non-null    float64\n",
            " 1   Price   400 non-null    int64  \n",
            " 2   Urban   400 non-null    object \n",
            " 3   US      400 non-null    object \n",
            "dtypes: float64(1), int64(1), object(2)\n",
            "memory usage: 12.6+ KB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sales</th>\n",
              "      <th>Price</th>\n",
              "      <th>Urban</th>\n",
              "      <th>US</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.50</td>\n",
              "      <td>120</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.22</td>\n",
              "      <td>83</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.06</td>\n",
              "      <td>80</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.40</td>\n",
              "      <td>97</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.15</td>\n",
              "      <td>128</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sales  Price Urban   US\n",
              "0   9.50    120   Yes  Yes\n",
              "1  11.22     83   Yes  Yes\n",
              "2  10.06     80   Yes  Yes\n",
              "3   7.40     97   Yes  Yes\n",
              "4   4.15    128   Yes   No"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Slice the columns to analyze from the original dataset\n",
        "dt = cs[['Sales', 'Price', 'Urban', 'US']]\n",
        "dt.info()\n",
        "dt.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "2lfa12m101hJ",
        "outputId": "b7a2fd19-6dc1-4fdd-a0c2-b3bb90d3b742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Sales   400 non-null    float64\n",
            " 1   Price   400 non-null    int64  \n",
            " 2   Urban   400 non-null    int64  \n",
            " 3   US      400 non-null    int64  \n",
            "dtypes: float64(1), int64(3)\n",
            "memory usage: 12.6 KB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\3370123073.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dt[i] = dt[i].map({'Yes' : 1,\n",
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\3370123073.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dt[i] = dt[i].map({'Yes' : 1,\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sales</th>\n",
              "      <th>Price</th>\n",
              "      <th>Urban</th>\n",
              "      <th>US</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.50</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.22</td>\n",
              "      <td>83</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.06</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.40</td>\n",
              "      <td>97</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.15</td>\n",
              "      <td>128</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sales  Price  Urban  US\n",
              "0   9.50    120      1   1\n",
              "1  11.22     83      1   1\n",
              "2  10.06     80      1   1\n",
              "3   7.40     97      1   1\n",
              "4   4.15    128      1   0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create dummy variables for categorical values\n",
        "_cate = ['Urban', 'US']\n",
        "for i in _cate:\n",
        "  dt[i] = dt[i].map({'Yes' : 1,\n",
        "                     'No': 0})\n",
        "dt.info()\n",
        "dt.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJnX8irsEt3e",
        "outputId": "60d5a32c-f751-4ac3-8ecb-44b5b8ef9421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          Urban        US\n",
            "Urban  1.000000  0.047085\n",
            "US     0.047085  1.000000\n"
          ]
        }
      ],
      "source": [
        "# check the correlation between the qualitative variables\n",
        "check_corr = dt[['Urban', 'US']]\n",
        "print(check_corr.corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUNzQRyIziNb"
      },
      "outputs": [],
      "source": [
        "# Split predictors and response variable\n",
        "X = dt[['Price', 'Urban', 'US']]\n",
        "y = dt['Sales']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omwibh4Z8z8i"
      },
      "outputs": [],
      "source": [
        "# Fit the multiple linear regression model\n",
        "Xa = sm.add_constant(X)\n",
        "lr1= sm.OLS(y, Xa)\n",
        "fit_1= lr1.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqb_VkxE9BbB",
        "outputId": "056ef9fc-38e2-41b7-a5df-4347bdf45df1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  Sales   R-squared:                       0.239\n",
            "Model:                            OLS   Adj. R-squared:                  0.234\n",
            "Method:                 Least Squares   F-statistic:                     41.52\n",
            "Date:                Wed, 06 Apr 2022   Prob (F-statistic):           2.39e-23\n",
            "Time:                        21:10:40   Log-Likelihood:                -927.66\n",
            "No. Observations:                 400   AIC:                             1863.\n",
            "Df Residuals:                     396   BIC:                             1879.\n",
            "Df Model:                           3                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         13.0435      0.651     20.036      0.000      11.764      14.323\n",
            "Price         -0.0545      0.005    -10.389      0.000      -0.065      -0.044\n",
            "Urban         -0.0219      0.272     -0.081      0.936      -0.556       0.512\n",
            "US             1.2006      0.259      4.635      0.000       0.691       1.710\n",
            "==============================================================================\n",
            "Omnibus:                        0.676   Durbin-Watson:                   1.912\n",
            "Prob(Omnibus):                  0.713   Jarque-Bera (JB):                0.758\n",
            "Skew:                           0.093   Prob(JB):                        0.684\n",
            "Kurtosis:                       2.897   Cond. No.                         628.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "# Overview the result of the modeling\n",
        "print(fit_1.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZn45yT6vC3N"
      },
      "source": [
        "## (b) Provide an interpretation of each coefficient in the model.\n",
        "\n",
        " - The coefficients of the model are shown in (a) OLS Regression Results above. \n",
        "  - $ \\hat{\\beta_{0}} $ : 13.0435\n",
        "  - $ \\hat{\\beta_{Price}} $ : -0.0545\n",
        "  - $ \\hat{\\beta_{Urban}} $ : -0.0219\n",
        "  - $ \\hat{\\beta_{US}} $ : 1.2006\n",
        " - The coefficient of the quantitative predictor 'Price' is -0.0545, which quantifies the average effect of one unit increase in Price on Sales while other predictors are fixed. That is, **one unit increase of Price is associated with the drop of 0.0545 unit in Sales.** \n",
        " - The coefficient of the qualitative predictor 'Urban' is -0.0219, which means **the Sales in urban area may be lower than those not in urban area by -0.0219 unit on average**, if other predictors are fixed.\n",
        " - The coefficient of the qualitative predictor 'US' is 1.2006, which means **the Sales in the US is 1.2006 unit higher than those not in the US**, if other predictors are fixed.\n",
        " - The intecept is the baseline, which is **the average of the Sales where the Price is zero, and neither in the US nor in the Urban.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vopeV6wvmid"
      },
      "source": [
        "## (c) Write out the model in equation form, being careful to handle the qualitative variables properly.\n",
        "$$ Y_{Sales} = 13.0435 -0.0545X_{Price} -0.0219X_{Urban} +1.2006X_{US} $$ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj19_g8S8Zph"
      },
      "source": [
        "## (d) For which predictor variable j can you reject the null hypothesis $ H_{0} : β_{j} =0 $ ?\n",
        "\n",
        " - The P-value ($P>\\vert t\\vert $) shown in (a) OLS Regresion Results above indicates the probability to accept the null hypothesis.\n",
        " - **$ X_{Price} $ and $ X_{US} $** reject the null hypothesis, since the P-value is low enough (close to 0).\n",
        " - $ X_{Urban} $, however, whose P-value is high(0.936), does not reject the null hypothesis. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyCK7nq4-mdX"
      },
      "source": [
        "## (e) On the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is evidence of association with the outcome.\n",
        "\n",
        " - The new model contains only 2 predictors $ X_{Price} $ and $ X_{US} $, whose P-values are close to 0. That is, these predictors are significant.\n",
        " - The results of the new smaller model is below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Ao3QyKBWmR",
        "outputId": "4d4c2bd9-6eff-45b6-e425-017a704a8228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  Sales   R-squared:                       0.239\n",
            "Model:                            OLS   Adj. R-squared:                  0.235\n",
            "Method:                 Least Squares   F-statistic:                     62.43\n",
            "Date:                Wed, 06 Apr 2022   Prob (F-statistic):           2.66e-24\n",
            "Time:                        21:10:57   Log-Likelihood:                -927.66\n",
            "No. Observations:                 400   AIC:                             1861.\n",
            "Df Residuals:                     397   BIC:                             1873.\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         13.0308      0.631     20.652      0.000      11.790      14.271\n",
            "Price         -0.0545      0.005    -10.416      0.000      -0.065      -0.044\n",
            "US             1.1996      0.258      4.641      0.000       0.692       1.708\n",
            "==============================================================================\n",
            "Omnibus:                        0.666   Durbin-Watson:                   1.912\n",
            "Prob(Omnibus):                  0.717   Jarque-Bera (JB):                0.749\n",
            "Skew:                           0.092   Prob(JB):                        0.688\n",
            "Kurtosis:                       2.895   Cond. No.                         607.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "# Fit the smaller model and overview the result of the modeling\n",
        "\n",
        "X = dt[['Price', 'US']]\n",
        "y = dt['Sales']\n",
        "Xe = sm.add_constant(X)\n",
        "lr2 = sm.OLS(y, Xe)\n",
        "fit_2= lr2.fit()\n",
        "print(fit_2.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUaZnNH2__BE"
      },
      "source": [
        "## (f) How well do the models in Part (a) and Part (e) fit the data? Compare the two models. Can you say one model is better than the other based on $ R^{2} $ ?\n",
        "\n",
        " - The $R^{2}$ of the first regression model (a) is 0.239, and that of the smaller model (e) is same, **which does not give any implications on the improvement of the model performance.**\n",
        " - However, F-statistic, which also indicates the overall performance of the model, is higher in the model (e). Thus, **the model (e) is better than model (a).** \n",
        " - In general, **small models have more advantages than complex models in terms of the interpretability and predictive accurracy** on the datapoints unobserved yet. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fIpvMwiHAB_"
      },
      "source": [
        "## (g) Using the model from (e), obtain 95% confidence intervals for the coefficient(s).\n",
        "\n",
        " - the 95% confidence interval for each coefficient can be calculated by the formula below.\n",
        "  - $ \\hat{\\beta} \\pm 2*SE(\\hat{\\beta}) $\n",
        " - The confidence interval of the coefficient of $ X_{Price} $ (or, $ \\hat{\\beta_{Price}} $)is **between -0.065 and -0.044.**\n",
        " - The confidence interval of the coefficient of $ X_{US} $ (or, $ \\hat{\\beta_{US}} $)is **between 0.684 and 1.716.**\n",
        " - The confidence interval of intercept(or, $ \\hat{\\beta_{0}} $) is **between 11.769 and 14.293.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vaXXGr6PZ3a"
      },
      "outputs": [],
      "source": [
        "def conf_interval(_coeff: float, _se:float, _lambda:float) -> None:\n",
        "  start = _coeff - _lambda*_se\n",
        "  end = _coeff + _lambda*_se\n",
        "  return print([round(start,3), round(end,3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y5YyKlCOnJy",
        "outputId": "18587dd8-59d4-4097-faeb-1c9d8de504fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.065, -0.044]\n",
            "[0.684, 1.716]\n",
            "[11.769, 14.293]\n"
          ]
        }
      ],
      "source": [
        "interc_coeff = 13.0308\n",
        "interc_se = 0.631\n",
        "\n",
        "price_coeff =  -0.0545\n",
        "price_se = 0.005\n",
        "\n",
        "us_coeff = 1.1996\n",
        "us_se = 0.258\n",
        "\n",
        "conf_interval(price_coeff, price_se, 2)\n",
        "conf_interval(us_coeff, us_se, 2)\n",
        "conf_interval(interc_coeff, interc_se, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijhU3xguE87D"
      },
      "source": [
        "# 2. Default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtlTi36uNXlS"
      },
      "source": [
        "## (a) Fit a logistic regression model that uses income and balance to predict default using the validation set approach, and estimate the test error of this model. In order to do this, you must perform the following steps:\n",
        " - Split the sample set into a training set and a validation set.\n",
        " - Fit a multiple logistic regression model using only the training observations.\n",
        " - Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5.\n",
        " - Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZnYkz6ISS47"
      },
      "outputs": [],
      "source": [
        "# Set random seed \n",
        "np.random.seed(25212)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "8EEKjkNOE4hi",
        "outputId": "75c2b224-d974-412c-c8df-e29fe44c923f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   default  10000 non-null  int64  \n",
            " 1   student  10000 non-null  int64  \n",
            " 2   balance  10000 non-null  float64\n",
            " 3   income   10000 non-null  float64\n",
            "dtypes: float64(2), int64(2)\n",
            "memory usage: 312.6 KB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>default</th>\n",
              "      <th>student</th>\n",
              "      <th>balance</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>729.526495</td>\n",
              "      <td>44361.625074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>817.180407</td>\n",
              "      <td>12106.134700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1073.549164</td>\n",
              "      <td>31767.138947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>529.250605</td>\n",
              "      <td>35704.493935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>785.655883</td>\n",
              "      <td>38463.495879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   default  student      balance        income\n",
              "0        0        0   729.526495  44361.625074\n",
              "1        0        1   817.180407  12106.134700\n",
              "2        0        0  1073.549164  31767.138947\n",
              "3        0        0   529.250605  35704.493935\n",
              "4        0        0   785.655883  38463.495879"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create dummy variables for categorical variables\n",
        "_cate2 = ['default', 'student']\n",
        "for i in _cate2:\n",
        "  df[i] = df[i].map({'Yes' : 1,\n",
        "                     'No': 0})\n",
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcQIGBXqeJbb"
      },
      "outputs": [],
      "source": [
        "# Slice the columns to analyze from the original dataset\n",
        "dff = df[['default', 'income', 'balance']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-f4HPyv1uki",
        "outputId": "f67c1fbf-8fee-4ffc-d781-11e2027186a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           income   balance\n",
            "income   1.000000 -0.152243\n",
            "balance -0.152243  1.000000\n"
          ]
        }
      ],
      "source": [
        "# check the correlation between the qualitative predictors\n",
        "check_corr2 = dff[['income', 'balance']]\n",
        "print(check_corr2.corr())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptnBQNI4lB4D"
      },
      "source": [
        " - Split the sample set randomly shuffled into a training set and a validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stDZHi5HSx2a"
      },
      "outputs": [],
      "source": [
        "train, validate = np.split(dff.sample(frac=1, random_state=25212), [int(0.5*len(dff))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajUCxx8Reqv0"
      },
      "outputs": [],
      "source": [
        "# Split predictors and response variable \n",
        "X_train = train[['income','balance']]\n",
        "y_train = train['default']\n",
        "X_validate = validate[['income','balance']]\n",
        "y_validate = validate['default']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEUqZ4jDddgG",
        "outputId": "e4d4b1fc-5752-46bb-ff6e-fdcb4d7b9eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5000, 2)\n",
            "(5000,)\n",
            "(5000, 2)\n",
            "(5000,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_validate.shape)\n",
        "print(y_validate.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5IYiHHJlFC9"
      },
      "source": [
        " - Fit a multiple logistic regression model using only the training observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NnMEsRBdkmr",
        "outputId": "e640cbe4-01b8-43a4-bac6-f6aab07e54ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.076068\n",
            "         Iterations 10\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                default   No. Observations:                 5000\n",
            "Model:                          Logit   Df Residuals:                     4997\n",
            "Method:                           MLE   Df Model:                            2\n",
            "Date:                Wed, 06 Apr 2022   Pseudo R-squ.:                  0.4680\n",
            "Time:                        21:12:44   Log-Likelihood:                -380.34\n",
            "converged:                       True   LL-Null:                       -714.94\n",
            "Covariance Type:            nonrobust   LLR p-value:                4.836e-146\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        -11.8739      0.640    -18.540      0.000     -13.129     -10.619\n",
            "income      2.383e-05   7.09e-06      3.363      0.001    9.94e-06    3.77e-05\n",
            "balance        0.0058      0.000     17.451      0.000       0.005       0.006\n",
            "==============================================================================\n",
            "\n",
            "Possibly complete quasi-separation: A fraction 0.16 of observations can be\n",
            "perfectly predicted. This might indicate that there is complete\n",
            "quasi-separation. In this case some parameters will not be identified.\n"
          ]
        }
      ],
      "source": [
        "X_train = sm.add_constant(X_train)\n",
        "X_validate = sm.add_constant(X_validate)\n",
        "lg = sm.Logit(y_train, X_train)\n",
        "fit_lg= lg.fit()\n",
        "print(fit_lg.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taeuB8pAlKnx"
      },
      "source": [
        " - Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9ttpykJQ2iH"
      },
      "outputs": [],
      "source": [
        "y_hat = fit_lg.predict(X_validate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tveAJS5Yq5S"
      },
      "outputs": [],
      "source": [
        "pred_actual= pd.DataFrame(data = y_hat, columns=['prob'])\n",
        "pred_actual.insert(loc = 1, column = 'default_predicted', value = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ne07etFlm4p"
      },
      "source": [
        " - Classify the individual to the default category if the posterior probability is greater than 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhA1Xqz2RaW_"
      },
      "outputs": [],
      "source": [
        "def convert_to_default(x: float) -> int:\n",
        "  if x > 0.5:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOW_n-2bSKYH",
        "outputId": "5acce1ac-be32-4e1f-ad48-265e2d525994"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\2368642204.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  pred_actual['default_predicted'][i] = convert_to_default(pred_actual['prob'][i])\n"
          ]
        }
      ],
      "source": [
        "for i in pred_actual.index:\n",
        "  pred_actual['default_predicted'][i] = convert_to_default(pred_actual['prob'][i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "oBxzMxckUsFa",
        "outputId": "afcdab63-88ea-43e2-8bc2-7a172c3d5755"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prob</th>\n",
              "      <th>default_predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6210</th>\n",
              "      <td>0.001774</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5693</th>\n",
              "      <td>0.024642</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3425</th>\n",
              "      <td>0.000011</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>0.001609</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5327</th>\n",
              "      <td>0.000441</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1211</th>\n",
              "      <td>0.001243</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5818</th>\n",
              "      <td>0.032595</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2176</th>\n",
              "      <td>0.000741</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2281</th>\n",
              "      <td>0.002434</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9595</th>\n",
              "      <td>0.100588</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          prob default_predicted\n",
              "6210  0.001774                 0\n",
              "5693  0.024642                 0\n",
              "3425  0.000011                 0\n",
              "1455  0.001609                 0\n",
              "5327  0.000441                 0\n",
              "...        ...               ...\n",
              "1211  0.001243                 0\n",
              "5818  0.032595                 0\n",
              "2176  0.000741                 0\n",
              "2281  0.002434                 0\n",
              "9595  0.100588                 0\n",
              "\n",
              "[5000 rows x 2 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The probability of default and the predicted default category of each individual in the validation set\n",
        "pred_actual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJA6qJ4GUwiy",
        "outputId": "4693784e-8ba1-4454-c149-f01533d92947"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    4934\n",
              "1      66\n",
              "Name: default_predicted, dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# the number of the individuals who are predicted to be default is 66\n",
        "pred_actual['default_predicted'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neB5ojI3ldRe"
      },
      "source": [
        " - Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified.\n",
        "  - **Misclassification error : 0.027**\n",
        "  - **False positive rate : 0.003**\n",
        "  - **False_negative_rate : 0.702** \n",
        "  - False negative rate is too high; that is to say, **this model fails to predict individuals to be default actually.** This issue may result from the imbalanced ratio of the labels. \n",
        "\n",
        " - Performance Metrics\n",
        "  - Recall(or True positive rate, sensitivity) : 0.298\n",
        "  - Precision : 0.773\n",
        "  - AUC : 0.947\n",
        "  - The recall is too low, which indicates the same issue as above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "tIkw7ZkFVvDh",
        "outputId": "5fdba24e-d6a8-42cb-f97c-e27a61c38cdf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prob</th>\n",
              "      <th>default_predicted</th>\n",
              "      <th>default_actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6210</th>\n",
              "      <td>0.001774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5693</th>\n",
              "      <td>0.024642</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3425</th>\n",
              "      <td>0.000011</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>0.001609</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5327</th>\n",
              "      <td>0.000441</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1211</th>\n",
              "      <td>0.001243</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5818</th>\n",
              "      <td>0.032595</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2176</th>\n",
              "      <td>0.000741</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2281</th>\n",
              "      <td>0.002434</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9595</th>\n",
              "      <td>0.100588</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          prob default_predicted  default_actual\n",
              "6210  0.001774                 0               0\n",
              "5693  0.024642                 0               0\n",
              "3425  0.000011                 0               0\n",
              "1455  0.001609                 0               0\n",
              "5327  0.000441                 0               0\n",
              "...        ...               ...             ...\n",
              "1211  0.001243                 0               0\n",
              "5818  0.032595                 0               0\n",
              "2176  0.000741                 0               0\n",
              "2281  0.002434                 0               0\n",
              "9595  0.100588                 0               0\n",
              "\n",
              "[5000 rows x 3 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The predicted default category and the actual default status of each individual in the validation set\n",
        "pred_actual.insert(loc =2, column = 'default_actual', value = y_validate)\n",
        "pred_actual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R2zt00AVv6K",
        "outputId": "e2075b05-4105-4910-85bb-c6c91e02608f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    4829\n",
              "1     171\n",
              "Name: default_actual, dtype: int64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# the number of the individuals who are actually default is 171\n",
        "pred_actual['default_actual'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBAjC6uHWVrU",
        "outputId": "ca21e3e5-ae07-4b12-8912-695f3957ecea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[4814, 15], [120, 51]]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Construct a confusion matrix to calculate the validation set error\n",
        "confusion_matrix = [[0,0],[0,0]]\n",
        "for i in pred_actual.index:\n",
        "  if pred_actual['default_predicted'][i] == 0:\n",
        "    if pred_actual['default_actual'][i] == 0:\n",
        "      confusion_matrix[0][0] += 1 # True Negative\n",
        "    else :\n",
        "      confusion_matrix[1][0] += 1 # False Negative\n",
        "  else :\n",
        "    if pred_actual['default_actual'][i] == 0:\n",
        "      confusion_matrix[0][1] += 1 # False Positive\n",
        "    else :\n",
        "      confusion_matrix[1][1] += 1 # True Positive\n",
        "confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGRpATsUYXRd",
        "outputId": "99f46af4-7dc4-4820-fac5-c08e1b03481a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.027\n"
          ]
        }
      ],
      "source": [
        "# Calculate the misclassification error of prediction model\n",
        "a_misclassification_error = (confusion_matrix[0][1] + confusion_matrix[1][0]) / (confusion_matrix[0][0] + confusion_matrix[0][1] + confusion_matrix[1][0] + confusion_matrix[1][1])\n",
        "print(a_misclassification_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFNUYePTaacG",
        "outputId": "eb9efa48-df0a-4633-ab37-cdf76b79956d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "false positive rate :  0.003\n",
            "false negative rate :  0.702\n",
            "True positive rate (Recall, Power, Sensitivity):  0.298\n",
            "precision :  0.773\n",
            "specificity :  0.997\n"
          ]
        }
      ],
      "source": [
        "# Other performance metrics to consider the imbalanced ratio of the labels('default')\n",
        "a_false_positive_rate = confusion_matrix[0][1] / (confusion_matrix[0][0] + confusion_matrix[0][1]) \n",
        "a_false_negative_rate = confusion_matrix[1][0] / (confusion_matrix[1][0] + confusion_matrix[1][1])\n",
        "a_true_positive_rate = confusion_matrix[1][1] / (confusion_matrix[1][0]+confusion_matrix[1][1])# sensitivity, or recall\n",
        "a_precision = confusion_matrix[1][1] / (confusion_matrix[0][1]+confusion_matrix[1][1])\n",
        "a_specificity = 1-a_false_positive_rate\n",
        "\n",
        "print(\"false positive rate : \", round(a_false_positive_rate,3))\n",
        "print(\"false negative rate : \", round(a_false_negative_rate,3))\n",
        "print(\"True positive rate (Recall, Power, Sensitivity): \", round(a_true_positive_rate,3))\n",
        "print(\"precision : \", round(a_precision,3))\n",
        "print(\"specificity : \", round(a_specificity,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m6WnawmgHBE",
        "outputId": "ea463d83-8771-42d6-9308-c810fb3cea88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.947"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# AUC\n",
        "from sklearn import metrics\n",
        "y_actual = np.array(pred_actual['default_actual'])\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_actual, y_hat)\n",
        "round(metrics.auc(fpr, tpr),3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa7tTUnVNyu2"
      },
      "source": [
        "## (b) Provide an interpretation of each coefficient in the trained model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tb8UXoepW4d"
      },
      "source": [
        " - The coefficients of the model are shown in (a) the Logit Regression Result above.\n",
        "  - $ \\hat{\\beta_{0}} $ : -11.8739\n",
        "  - $ \\hat{\\beta_{income}} $ : 2.383e-05\n",
        "  - $ \\hat{\\beta_{balance}} $ : 0.0058\n",
        " - The $ \\hat{\\beta} $ in logistic regression indicates that how much the log odds of the default changes on average with one unit increase of the predictor, if values of other predictors are fixed.\n",
        "  - $ \\hat{\\beta_{income}} $ indicates that **increasing income by one unit changes the log odds slightly by 2.383e-05 on average.** Considering the P-value is low, the income is a significant variable.\n",
        "  - $ \\hat{\\beta_{balance}} $ also indicates that **the increasing balance by one unit associated with the increasing change of the log odds by 0.0058 on average.** Since the P-value is close to 0, the balance can be regarded as a significant predictor. \n",
        "  - The intercept, or $ \\hat{\\beta_{0}} $ is **the log odds when both the income and balance are zero.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9QPYEEmN4Xm"
      },
      "source": [
        "## (c) Perform 5-fold cross-validation using the same model as in Part (a). How does the validation error of the cross-validation the differ from to the results in Part (a)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE_9bW6K9FOD"
      },
      "source": [
        " - Sample n = len(dataset) / k(=5) datapoints, and split them as the validation set.\n",
        " - Other datapoints make up training set.\n",
        " - Fit a logistic regression model, calcuate misclassification error metrics each.\n",
        " - Repeat the sequence by sampling without replacement for k(=5) times. \n",
        " - Average the errors from k(=5) validation sets and get the validation error of the cross-validation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ShAdPy9p2V7"
      },
      "outputs": [],
      "source": [
        "def c_k_fold_cv(dataset: pd.DataFrame, K: int):\n",
        "  val_used_rows = []\n",
        "  valid_rows = []\n",
        "  \n",
        "  MisClassError = []\n",
        "  FalsePosR = []\n",
        "  FalseNegR = []\n",
        "  Recall = []\n",
        "  Precision = []\n",
        "\n",
        "  N = int(dataset.shape[0]/K)\n",
        "\n",
        "  for times in range(K):\n",
        "    _copy = dataset.copy()\n",
        "    _sample_space = _copy.drop(val_used_rows) # delete the rows which was the validation data previouly in order to avoid overlapping issue on the posterior validation sets\n",
        "    valid_set = _sample_space.sample(n = N, random_state = 25212) # sample the same size of datapoints for each fold\n",
        "    for j in valid_set.index:\n",
        "      val_used_rows.append(j) # register the rows once used as the validation data\n",
        "      valid_rows.append(j)  # register the rows used as the validation data currently\n",
        "    train_set = _copy.drop(valid_rows) # delete the rows used as the validation data currently from the train set\n",
        "    valid_rows.clear() # clear the register memory of the current validation set\n",
        "\n",
        "    X_train = train_set[['income', 'balance']]\n",
        "    y_train = train_set['default']\n",
        "    X_valid = valid_set[['income','balance']]\n",
        "    y_valid = valid_set['default']\n",
        "    X_train = sm.add_constant(X_train)\n",
        "    X_valid = sm.add_constant(X_valid)\n",
        "    lg_model = sm.Logit(y_train, X_train)\n",
        "    fit_lg_model = lg_model.fit()\n",
        "    y_hat = fit_lg_model.predict(X_valid)\n",
        "\n",
        "    tmp= pd.DataFrame(data = y_hat, columns=['prob'])\n",
        "    tmp.insert(loc = 1, column = 'default_predicted', value = None)\n",
        "    for k in tmp.index:\n",
        "      tmp['default_predicted'][k] = convert_to_default(tmp['prob'][k])\n",
        "    tmp.insert(loc=2, column = 'default_actual', value = y_valid)\n",
        "\n",
        "    con_mat = [[0,0],[0,0]]\n",
        "    for l in tmp.index:\n",
        "      if tmp['default_predicted'][l] == 0:\n",
        "        if tmp['default_actual'][l] == 0:\n",
        "          con_mat[0][0] += 1 \n",
        "        else :\n",
        "          con_mat[1][0] += 1 \n",
        "      else :\n",
        "        if tmp['default_actual'][l] == 0:\n",
        "          con_mat[0][1] += 1 \n",
        "        else :\n",
        "          con_mat[1][1] += 1 \n",
        "\n",
        "    misclass_error = (con_mat[0][1] + con_mat[1][0]) / (con_mat[0][0] + con_mat[0][1] + con_mat[1][0] + con_mat[1][1])\n",
        "    MisClassError.append(misclass_error)\n",
        "    false_positive_rate = con_mat[0][1] / (con_mat[0][0] + con_mat[0][1])\n",
        "    FalsePosR.append(false_positive_rate)\n",
        "    false_negative_rate = con_mat[1][0] / (con_mat[1][0] + con_mat[1][1])\n",
        "    FalseNegR.append(false_negative_rate)\n",
        "    recall = con_mat[1][1] / (con_mat[1][0]+con_mat[1][1])\n",
        "    Recall.append(recall)\n",
        "    precision = con_mat[1][1] / (con_mat[0][1]+con_mat[1][1])\n",
        "    Precision.append(precision)\n",
        "\n",
        "  c_misclass_error = sum(MisClassError) / K\n",
        "  c_false_positive_rate = sum(FalsePosR) / K\n",
        "  c_false_negative_rate = sum(FalseNegR) / K\n",
        "  c_recall = sum(Recall) / K\n",
        "  c_precision = sum(Precision) / K\n",
        "\n",
        "  return c_misclass_error, c_false_positive_rate, c_false_negative_rate, c_recall, c_precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3xQk2rp4ip1",
        "outputId": "76001b79-42a8-448e-be9e-858fd6b60142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.080578\n",
            "         Iterations 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\967960528.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tmp['default_predicted'][k] = convert_to_default(tmp['prob'][k])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.078300\n",
            "         Iterations 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\967960528.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tmp['default_predicted'][k] = convert_to_default(tmp['prob'][k])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.080147\n",
            "         Iterations 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\967960528.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tmp['default_predicted'][k] = convert_to_default(tmp['prob'][k])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.076528\n",
            "         Iterations 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\967960528.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tmp['default_predicted'][k] = convert_to_default(tmp['prob'][k])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.079108\n",
            "         Iterations 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\967960528.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tmp['default_predicted'][k] = convert_to_default(tmp['prob'][k])\n"
          ]
        }
      ],
      "source": [
        "c_misclass_error, c_false_positive_rate, c_false_negative_rate, c_recall, c_precision = c_k_fold_cv(dff,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBZe6iG0ktau",
        "outputId": "d47a5bba-1c4a-42a3-b8f8-ce496261e3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MISCLASS_ERROR : 0.026 FPR : 0.004 FNR : 0.675 RECALL : 0.325 PRECISION : 0.74\n"
          ]
        }
      ],
      "source": [
        "print('MISCLASS_ERROR :', round(c_misclass_error,3,), \n",
        "      'FPR :', round(c_false_positive_rate,3), \n",
        "      'FNR :', round(c_false_negative_rate,3), \n",
        "      'RECALL :', round(c_recall,3), \n",
        "      'PRECISION :', round(c_precision, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob0pcrrWZtcQ"
      },
      "source": [
        " - Check how much the validation error of the 5-fold cross-validation differ from to the results in Part (a).\n",
        "  - The overall misclassification error has been slightly improved. \n",
        "  - **The metrics such as FNR and recall has been improved,** which are associated with predicting the actual default status. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BzCu5sKRa4SO",
        "outputId": "2265c1f0-1b7e-4f2e-9492-e238b7f25b45"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model (a)</th>\n",
              "      <th>model (c)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MISCLASS_ERROR</th>\n",
              "      <td>0.027</td>\n",
              "      <td>0.026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FPR</th>\n",
              "      <td>0.003</td>\n",
              "      <td>0.004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FNR</th>\n",
              "      <td>0.702</td>\n",
              "      <td>0.675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RECALL</th>\n",
              "      <td>0.298</td>\n",
              "      <td>0.325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRCSN</th>\n",
              "      <td>0.773</td>\n",
              "      <td>0.740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                model (a)  model (c)\n",
              "MISCLASS_ERROR      0.027      0.026\n",
              "FPR                 0.003      0.004\n",
              "FNR                 0.702      0.675\n",
              "RECALL              0.298      0.325\n",
              "PRCSN               0.773      0.740"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comp1 = {'MISCLASS_ERROR': [round(a_misclassification_error,3), round(c_misclass_error,3)], \n",
        "        'FPR': [round(a_false_positive_rate,3), round(c_false_positive_rate,3)], \n",
        "        'FNR': [round(a_false_negative_rate,3), round(c_false_negative_rate,3)], \n",
        "        'RECALL': [round(a_true_positive_rate,3), round(c_recall,3)], \n",
        "        'PRCSN': [round(a_precision,3), round(c_precision,3)] }\n",
        "\n",
        "comparison1 = pd.DataFrame.from_dict(comp1, orient='index')\n",
        "comparison1.columns = ['model (a)', 'model (c)']\n",
        "comparison1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYbOqlyrOAXs"
      },
      "source": [
        "## (d)  Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the 5-fold cross-validation set approach. Comment on whether or not including a dummy variable for student would lead to a reduction in the test error rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOhbHP21MGOp"
      },
      "outputs": [],
      "source": [
        "def d_k_fold_cv(dataset: pd.DataFrame, K: int):\n",
        "  val_used_rows = []\n",
        "  valid_rows = []\n",
        "  \n",
        "  MisClassError = []\n",
        "  FalsePosR = []\n",
        "  FalseNegR = []\n",
        "  Recall = []\n",
        "  Precision = []\n",
        "\n",
        "  N = int(dataset.shape[0]/K)\n",
        "\n",
        "  for times in range(K):\n",
        "    _copy = dataset.copy()\n",
        "    _sample_space = _copy.drop(val_used_rows) # delete the rows which was the validation data previouly in order to avoid overlapping issue on the posterior validation sets\n",
        "    valid_set = _sample_space.sample(n = N, random_state = 25212) # sample the same size of datapoints for each fold\n",
        "    for j in valid_set.index:\n",
        "      val_used_rows.append(j) # register the rows once used as the validation data\n",
        "      valid_rows.append(j)  # register the rows used as the validation data currently\n",
        "    train_set = _copy.drop(valid_rows) # delete the rows used as the validation data currently from the train set\n",
        "    valid_rows.clear() # clear the register memory of the current validation set\n",
        "\n",
        "    X_train = train_set[['income', 'balance', 'student']]\n",
        "    y_train = train_set['default']\n",
        "    X_valid = valid_set[['income','balance', 'student']]\n",
        "    y_valid = valid_set['default']\n",
        "    X_train = sm.add_constant(X_train)\n",
        "    X_valid = sm.add_constant(X_valid)\n",
        "    lg_model = sm.Logit(y_train, X_train)\n",
        "    fit_lg_model = lg_model.fit()\n",
        "    y_hat = fit_lg_model.predict(X_valid)\n",
        "\n",
        "    tmp= pd.DataFrame(data = y_hat, columns=['prob'])\n",
        "    tmp.insert(loc = 1, column = 'default_predicted', value = None)\n",
        "    for k in tmp.index:\n",
        "      tmp['default_predicted'][k] = convert_to_default(tmp['prob'][k])\n",
        "    tmp.insert(loc=2, column = 'default_actual', value = y_valid)\n",
        "\n",
        "    con_mat = [[0,0],[0,0]]\n",
        "    for l in tmp.index:\n",
        "      if tmp['default_predicted'][l] == 0:\n",
        "        if tmp['default_actual'][l] == 0:\n",
        "          con_mat[0][0] += 1 \n",
        "        else :\n",
        "          con_mat[1][0] += 1 \n",
        "      else :\n",
        "        if tmp['default_actual'][l] == 0:\n",
        "          con_mat[0][1] += 1 \n",
        "        else :\n",
        "          con_mat[1][1] += 1 \n",
        "\n",
        "    misclass_error = (con_mat[0][1] + con_mat[1][0]) / (con_mat[0][0] + con_mat[0][1] + con_mat[1][0] + con_mat[1][1])\n",
        "    MisClassError.append(misclass_error)\n",
        "    false_positive_rate = con_mat[0][1] / (con_mat[0][0] + con_mat[0][1])\n",
        "    FalsePosR.append(false_positive_rate)\n",
        "    false_negative_rate = con_mat[1][0] / (con_mat[1][0] + con_mat[1][1])\n",
        "    FalseNegR.append(false_negative_rate)\n",
        "    recall = con_mat[1][1] / (con_mat[1][0]+con_mat[1][1])\n",
        "    Recall.append(recall)\n",
        "    precision = con_mat[1][1] / (con_mat[0][1]+con_mat[1][1])\n",
        "    Precision.append(precision)\n",
        "\n",
        "  c_misclass_error = sum(MisClassError) / K\n",
        "  c_false_positive_rate = sum(FalsePosR) / K\n",
        "  c_false_negative_rate = sum(FalseNegR) / K\n",
        "  c_recall = sum(Recall) / K\n",
        "  c_precision = sum(Precision) / K\n",
        "\n",
        "  return c_misclass_error, c_false_positive_rate, c_false_negative_rate, c_recall, c_precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TBM5CcLqZKc",
        "outputId": "f3017cb7-57f6-47d2-e139-375b0f177b00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.080056\n",
            "         Iterations 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\1622079427.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tmp['default_predicted'][k] = convert_to_default(tmp['prob'][k])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.077876\n",
            "         Iterations 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\1622079427.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tmp['default_predicted'][k] = convert_to_default(tmp['prob'][k])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.079753\n",
            "         Iterations 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\1622079427.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tmp['default_predicted'][k] = convert_to_default(tmp['prob'][k])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.076220\n",
            "         Iterations 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\1622079427.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tmp['default_predicted'][k] = convert_to_default(tmp['prob'][k])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.078863\n",
            "         Iterations 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gsds_lsj\\AppData\\Local\\Temp\\ipykernel_12836\\1622079427.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tmp['default_predicted'][k] = convert_to_default(tmp['prob'][k])\n"
          ]
        }
      ],
      "source": [
        "d_misclass_error, d_false_positive_rate, d_false_negative_rate, d_recall, d_precision = d_k_fold_cv(df,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAf_ztnctD02"
      },
      "source": [
        " - Check the effect of dummy variable for 'Student'\n",
        "  - Including the dummy variable 'Student' **didn't help to reduce the validation error** (,or the estimated test error) model (c), as the overall misclassification error got higher, especially the FNR got worse.\n",
        "  - In this vein both the recall and precision score got worse in model (d), which including the 'Student' dummy variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P0oyFFccsbn9",
        "outputId": "13c0dbe1-cedb-4dc3-cdd2-13c67bd644ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model (c)</th>\n",
              "      <th>model (d)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MISCLASS_ERROR</th>\n",
              "      <td>0.026</td>\n",
              "      <td>0.027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FPR</th>\n",
              "      <td>0.004</td>\n",
              "      <td>0.004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FNR</th>\n",
              "      <td>0.675</td>\n",
              "      <td>0.680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RECALL</th>\n",
              "      <td>0.325</td>\n",
              "      <td>0.320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRCSN</th>\n",
              "      <td>0.740</td>\n",
              "      <td>0.731</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                model (c)  model (d)\n",
              "MISCLASS_ERROR      0.026      0.027\n",
              "FPR                 0.004      0.004\n",
              "FNR                 0.675      0.680\n",
              "RECALL              0.325      0.320\n",
              "PRCSN               0.740      0.731"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comp2 = {'MISCLASS_ERROR': [round(c_misclass_error,3), round(d_misclass_error,3)], \n",
        "        'FPR': [round(c_false_positive_rate,3), round(d_false_positive_rate,3)], \n",
        "        'FNR': [round(c_false_negative_rate,3), round(d_false_negative_rate,3)], \n",
        "        'RECALL': [round(c_recall,3), round(d_recall,3)], \n",
        "        'PRCSN': [round(c_precision,3), round(d_precision,3)] }\n",
        "\n",
        "comparison2 = pd.DataFrame.from_dict(comp2, orient='index')\n",
        "comparison2.columns = ['model (c)', 'model (d)']\n",
        "comparison2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHR-srL05Vs8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "hw1_multilinearreg_logit.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}